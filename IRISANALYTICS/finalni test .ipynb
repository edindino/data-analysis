{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('https://s3-us-west-2.amazonaws.com/patchworks-coding-challenge/amazon_alexa.tsv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    2286\n",
       "4     455\n",
       "1     161\n",
       "3     152\n",
       "2      96\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.rating.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merged_by_group = df_train.groupby([df_train.rating]).verified_reviews.apply(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a = pd.DataFrame(merged_by_group).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_1 = df_train.drop(['date','variation', 'feedback'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>verified_reviews</th>\n",
       "      <th>phrase_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Love my Echo!</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Loved it!</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Sometimes while playing a game, you can answer...</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>I have had a lot of fun with this thing. My 4 ...</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                   verified_reviews  phrase_len\n",
       "0       5                                      Love my Echo!          13\n",
       "1       5                                          Loved it!           9\n",
       "2       4  Sometimes while playing a game, you can answer...         195\n",
       "3       5  I have had a lot of fun with this thing. My 4 ...         172"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_1['phrase_len'] = [len(t) for t in df_train_1.verified_reviews]\n",
    "df_train_1.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Not much features.',\n",
       " u\"Stopped working after 2 weeks ,didn't follow commands!? Really fun when it was working?\",\n",
       " u'Alexa hardly came on..',\n",
       " u'Item no longer works after just 5 months of use. Will not connect to wifi and unresponsive to reset requests.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filtering out positive and negative reviews\n",
    "neg_phrases = df_train_1[df_train_1.rating == 1]\n",
    "neg_words = []\n",
    "for t in neg_phrases.verified_reviews:\n",
    "    neg_words.append(t)\n",
    "neg_words[:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"Not much features. Stopped working after 2 weeks ,didn't follow commands!? Really fun when it was wo\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_text = pd.Series(neg_words).str.cat(sep=' ')\n",
    "neg_text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Love my Echo! Loved it! I have had a lot of fun with this thing. My 4 yr old learns about dinosaurs,'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_phrases = df_train_1[df_train_1.rating == 5] ## 4 is positive sentiment\n",
    "pos_string = []\n",
    "for t in pos_phrases.verified_reviews:\n",
    "    pos_string.append(t)\n",
    "pos_text = pd.Series(pos_string).str.cat(sep=' ')\n",
    "pos_text[:100]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.85, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvector = CountVectorizer(stop_words='english',max_df = 0.85, ngram_range=(1,2))\n",
    "cvector.fit(df_train_1.verified_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23994"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cvector.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neg_matrix = cvector.transform(df_train_1[df_train_1.rating == 1].verified_reviews)\n",
    "som_neg_matrix = cvector.transform(df_train_1[df_train_1.rating == 2].verified_reviews)\n",
    "neu_matrix = cvector.transform(df_train_1[df_train_1.rating == 3].verified_reviews)\n",
    "som_pos_matrix = cvector.transform(df_train_1[df_train_1.rating == 4].verified_reviews)\n",
    "pos_matrix = cvector.transform(df_train_1[df_train_1.rating == 5].verified_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_words = neg_matrix.sum(axis=0)\n",
    "neg_words_freq = [(word, neg_words[0, idx]) for word, idx in cvector.vocabulary_.items()]\n",
    "neg_tf = pd.DataFrame(list(sorted(neg_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>echo</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>product</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dot</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Terms  negative\n",
       "0     echo        50\n",
       "1       34        46\n",
       "2   amazon        45\n",
       "3  product        27\n",
       "4      dot        27"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_tf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terms</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       negative\n",
       "Terms          \n",
       "the         263\n",
       "to          198\n",
       "it          191\n",
       "and         152\n",
       "is           85"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_tf_df = neg_tf.set_index('Terms')\n",
    "neg_tf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'som_neg_tf_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-0df8af7b9166>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msom_neg_words_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msom_neg_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msom_neg_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msom_neg_words_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Terms'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'some-negative'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msom_neg_tf_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'som_neg_tf_df' is not defined"
     ]
    }
   ],
   "source": [
    "som_neg_words = som_neg_matrix.sum(axis=0)\n",
    "som_neg_words_freq = [(word, som_neg_words[0, idx]) for word, idx in cvector.vocabulary_.items()]\n",
    "som_neg_tf = pd.DataFrame(list(sorted(som_neg_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','some-negative'])\n",
    "som_neg_tf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terms</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>echo</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alexa</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speaker</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>music</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         neutral\n",
       "Terms           \n",
       "echo          55\n",
       "alexa         53\n",
       "like          37\n",
       "speaker       30\n",
       "music         28"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neu_words = neu_matrix.sum(axis=0)\n",
    "neu_words_freq = [(word, neu_words[0, idx]) for word, idx in cvector.vocabulary_.items()]\n",
    "neu_words_tf = pd.DataFrame(list(sorted(neu_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','neutral'])\n",
    "neu_words_tf_df = neu_words_tf.set_index('Terms')\n",
    "neu_words_tf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>some-positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terms</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>echo</th>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alexa</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>music</th>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       some-positive\n",
       "Terms               \n",
       "echo             154\n",
       "great            127\n",
       "alexa            121\n",
       "like             118\n",
       "music            101"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "som_pos_words = som_pos_matrix.sum(axis=0)\n",
    "som_pos_words_freq = [(word, som_pos_words[0, idx]) for word, idx in cvector.vocabulary_.items()]\n",
    "som_pos_words_tf = pd.DataFrame(list(sorted(som_pos_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','some-positive'])\n",
    "som_pos_words_tf_df = som_pos_words_tf.set_index('Terms')\n",
    "som_pos_words_tf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terms</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>1771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>1634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>1477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my</th>\n",
       "      <td>980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       positive\n",
       "Terms          \n",
       "the        1849\n",
       "it         1771\n",
       "to         1634\n",
       "and        1477\n",
       "my          980"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_words = pos_matrix.sum(axis=0)\n",
    "pos_words_freq = [(word, pos_words[0, idx]) for word, idx in cvector.vocabulary_.items()]\n",
    "pos_words_tf = pd.DataFrame(list(sorted(pos_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','positive'])\n",
    "pos_words_tf_df = pos_words_tf.set_index('Terms')\n",
    "pos_words_tf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'neg_tf_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-d59084ef741a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mterm_freq_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneg_tf_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msom_neg_tf_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneu_words_tf_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msom_pos_words_tf_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos_words_tf_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'neg_tf_df' is not defined"
     ]
    }
   ],
   "source": [
    "term_freq_df = pd.concat([neg_tf_df,som_neg_tf_df,neu_words_tf_df,som_pos_words_tf_df,pos_words_tf_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>some-negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>some-positive</th>\n",
       "      <th>positive</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>263</td>\n",
       "      <td>193</td>\n",
       "      <td>290</td>\n",
       "      <td>687</td>\n",
       "      <td>1849</td>\n",
       "      <td>3282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>191</td>\n",
       "      <td>155</td>\n",
       "      <td>190</td>\n",
       "      <td>611</td>\n",
       "      <td>1771</td>\n",
       "      <td>2918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>198</td>\n",
       "      <td>173</td>\n",
       "      <td>227</td>\n",
       "      <td>593</td>\n",
       "      <td>1634</td>\n",
       "      <td>2825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>152</td>\n",
       "      <td>106</td>\n",
       "      <td>103</td>\n",
       "      <td>387</td>\n",
       "      <td>1477</td>\n",
       "      <td>2225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my</th>\n",
       "      <td>58</td>\n",
       "      <td>49</td>\n",
       "      <td>81</td>\n",
       "      <td>228</td>\n",
       "      <td>980</td>\n",
       "      <td>1396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>85</td>\n",
       "      <td>83</td>\n",
       "      <td>114</td>\n",
       "      <td>266</td>\n",
       "      <td>671</td>\n",
       "      <td>1219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>64</td>\n",
       "      <td>45</td>\n",
       "      <td>81</td>\n",
       "      <td>193</td>\n",
       "      <td>679</td>\n",
       "      <td>1062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>93</td>\n",
       "      <td>848</td>\n",
       "      <td>956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>echo</th>\n",
       "      <td>50</td>\n",
       "      <td>42</td>\n",
       "      <td>55</td>\n",
       "      <td>154</td>\n",
       "      <td>538</td>\n",
       "      <td>839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>79</td>\n",
       "      <td>67</td>\n",
       "      <td>47</td>\n",
       "      <td>117</td>\n",
       "      <td>524</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>46</td>\n",
       "      <td>37</td>\n",
       "      <td>51</td>\n",
       "      <td>156</td>\n",
       "      <td>499</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>71</td>\n",
       "      <td>41</td>\n",
       "      <td>64</td>\n",
       "      <td>170</td>\n",
       "      <td>422</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>have</th>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>59</td>\n",
       "      <td>146</td>\n",
       "      <td>467</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>127</td>\n",
       "      <td>570</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>54</td>\n",
       "      <td>52</td>\n",
       "      <td>69</td>\n",
       "      <td>153</td>\n",
       "      <td>354</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>59</td>\n",
       "      <td>119</td>\n",
       "      <td>418</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>but</th>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>86</td>\n",
       "      <td>179</td>\n",
       "      <td>302</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alexa</th>\n",
       "      <td>19</td>\n",
       "      <td>35</td>\n",
       "      <td>53</td>\n",
       "      <td>121</td>\n",
       "      <td>404</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>50</td>\n",
       "      <td>36</td>\n",
       "      <td>41</td>\n",
       "      <td>88</td>\n",
       "      <td>369</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>so</th>\n",
       "      <td>36</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>78</td>\n",
       "      <td>404</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       negative  some-negative  neutral  some-positive  positive  total\n",
       "the         263            193      290            687      1849   3282\n",
       "it          191            155      190            611      1771   2918\n",
       "to          198            173      227            593      1634   2825\n",
       "and         152            106      103            387      1477   2225\n",
       "my           58             49       81            228       980   1396\n",
       "is           85             83      114            266       671   1219\n",
       "for          64             45       81            193       679   1062\n",
       "love          6              1        8             93       848    956\n",
       "echo         50             42       55            154       538    839\n",
       "this         79             67       47            117       524    834\n",
       "with         46             37       51            156       499    789\n",
       "of           71             41       64            170       422    768\n",
       "have         60             24       59            146       467    756\n",
       "great        11              7       14            127       570    729\n",
       "that         54             52       69            153       354    682\n",
       "in           50             30       59            119       418    676\n",
       "but          43             35       86            179       302    645\n",
       "alexa        19             35       53            121       404    632\n",
       "on           50             36       41             88       369    584\n",
       "so           36             18       36             78       404    572"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_freq_df['total'] = term_freq_df['negative'] + term_freq_df['some-negative'] \\\n",
    "                                 + term_freq_df['neutral'] + term_freq_df['some-positive'] \\\n",
    "                                 +  term_freq_df['positive'] \n",
    "term_freq_df.sort_values(by='total', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Top 500 words in Amazon Reviews')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAHiCAYAAABRMkAtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwuAmSZLUJP4ffRpYn7nUbFQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pos = np.arange(500)\n",
    "plt.figure(figsize=(10,8))\n",
    "s = 1\n",
    "expected_zipf = [term_freq_df.sort_values(by='total', ascending=False)['total'][0]/(i+1)**s for i in y_pos]\n",
    "plt.bar(y_pos, term_freq_df.sort_values(by='total', ascending=False)['total'][:500], align='center', alpha=0.5)\n",
    "plt.plot(y_pos, expected_zipf, color='r', linestyle='--',linewidth=2,alpha=0.5)\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Top 500 words in Amazon Reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=10000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvec = CountVectorizer(stop_words='english',max_features=10000)\n",
    "cvec.fit(df_train_1.verified_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dinodjakovac/anaconda2/envs/gl-env/lib/python2.7/site-packages/ipykernel/__main__.py:34: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>some-negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>some-positive</th>\n",
       "      <th>positive</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>93</td>\n",
       "      <td>848</td>\n",
       "      <td>956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>echo</th>\n",
       "      <td>50</td>\n",
       "      <td>42</td>\n",
       "      <td>55</td>\n",
       "      <td>154</td>\n",
       "      <td>538</td>\n",
       "      <td>839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>127</td>\n",
       "      <td>570</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alexa</th>\n",
       "      <td>19</td>\n",
       "      <td>35</td>\n",
       "      <td>53</td>\n",
       "      <td>121</td>\n",
       "      <td>404</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>music</th>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>101</td>\n",
       "      <td>379</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>37</td>\n",
       "      <td>118</td>\n",
       "      <td>306</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>97</td>\n",
       "      <td>321</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>works</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>62</td>\n",
       "      <td>280</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easy</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>293</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sound</th>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>69</td>\n",
       "      <td>216</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>59</td>\n",
       "      <td>211</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "      <td>229</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dot</th>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>53</td>\n",
       "      <td>165</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>72</td>\n",
       "      <td>169</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product</th>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>169</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         negative  some-negative  neutral  some-positive  positive  total\n",
       "love            6              1        8             93       848    956\n",
       "echo           50             42       55            154       538    839\n",
       "great          11              7       14            127       570    729\n",
       "alexa          19             35       53            121       404    632\n",
       "music           8             24       28            101       379    540\n",
       "like           16             27       37            118       306    504\n",
       "use            13             20       18             97       321    469\n",
       "works          18              5       16             62       280    381\n",
       "easy            1              0        8             40       293    342\n",
       "sound           7             21       27             69       216    340\n",
       "just           18             25       21             59       211    334\n",
       "set            11              9       12             45       229    306\n",
       "dot            27             13       28             53       165    286\n",
       "good            7              8       21             72       169    277\n",
       "product        27             15       12             35       169    258"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_matrix = cvec.transform(df_train_1[df_train_1.rating == 1].verified_reviews)\n",
    "som_neg_matrix = cvec.transform(df_train_1[df_train_1.rating == 2].verified_reviews)\n",
    "neu_matrix = cvec.transform(df_train_1[df_train_1.rating == 3].verified_reviews)\n",
    "som_pos_matrix = cvec.transform(df_train_1[df_train_1.rating == 4].verified_reviews)\n",
    "pos_matrix = cvec.transform(df_train_1[df_train_1.rating == 5].verified_reviews)\n",
    "\n",
    "neg_words = neg_matrix.sum(axis=0)\n",
    "neg_words_freq = [(word, neg_words[0, idx]) for word, idx in cvec.vocabulary_.items()]\n",
    "neg_tf = pd.DataFrame(list(sorted(neg_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','negative'])\n",
    "\n",
    "neg_tf_df = neg_tf.set_index('Terms')\n",
    "\n",
    "\n",
    "som_neg_words = som_neg_matrix.sum(axis=0)\n",
    "som_neg_words_freq = [(word, som_neg_words[0, idx]) for word, idx in cvec.vocabulary_.items()]\n",
    "som_neg_tf = pd.DataFrame(list(sorted(som_neg_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','some-negative'])\n",
    "som_neg_tf_df = som_neg_tf.set_index('Terms')\n",
    "\n",
    "neu_words = neu_matrix.sum(axis=0)\n",
    "neu_words_freq = [(word, neu_words[0, idx]) for word, idx in cvec.vocabulary_.items()]\n",
    "neu_words_tf = pd.DataFrame(list(sorted(neu_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','neutral'])\n",
    "neu_words_tf_df = neu_words_tf.set_index('Terms')\n",
    "\n",
    "som_pos_words = som_pos_matrix.sum(axis=0)\n",
    "som_pos_words_freq = [(word, som_pos_words[0, idx]) for word, idx in cvec.vocabulary_.items()]\n",
    "som_pos_words_tf = pd.DataFrame(list(sorted(som_pos_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','some-positive'])\n",
    "som_pos_words_tf_df = som_pos_words_tf.set_index('Terms')\n",
    "\n",
    "pos_words = pos_matrix.sum(axis=0)\n",
    "pos_words_freq = [(word, pos_words[0, idx]) for word, idx in cvec.vocabulary_.items()]\n",
    "pos_words_tf = pd.DataFrame(list(sorted(pos_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','positive'])\n",
    "pos_words_tf_df = pos_words_tf.set_index('Terms')\n",
    "\n",
    "term_freq_df = pd.concat([neg_tf_df,som_neg_tf_df,neu_words_tf_df,som_pos_words_tf_df,pos_words_tf_df],axis=1)\n",
    "\n",
    "term_freq_df['total'] = term_freq_df['negative'] + term_freq_df['some-negative'] \\\n",
    "                                 + term_freq_df['neutral'] + term_freq_df['some-positive'] \\\n",
    "                                 +  term_freq_df['positive'] \n",
    "        \n",
    "term_freq_df.sort_values(by='total', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phrase = np.array(df_train_1['verified_reviews'])\n",
    "sentiments = np.array(df_train_1['rating'])\n",
    "# build train and test datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split    \n",
    "phrase_train, phrase_test, sentiments_train, sentiments_test = train_test_split(phrase, sentiments, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "## Build Bag-Of-Words on train phrases\n",
    "cv = CountVectorizer(stop_words='english',max_features=10000)\n",
    "cv_train_features = cv.fit_transform(phrase_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build TFIDF features on train reviews\n",
    "tv = TfidfVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1,2),\n",
    "                     sublinear_tf=True)\n",
    "tv_train_features = tv.fit_transform(phrase_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform test reviews into features\n",
    "cv_test_features = cv.transform(phrase_test)\n",
    "tv_test_features = tv.transform(phrase_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####Evaluation metrics\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, auc \n",
    "\n",
    "\n",
    "def get_metrics(true_labels, predicted_labels):\n",
    "    \n",
    "    print('Accuracy:', np.round(\n",
    "                        metrics.accuracy_score(true_labels, \n",
    "                                               predicted_labels),\n",
    "                        4))\n",
    "    print('Precision:', np.round(\n",
    "                        metrics.precision_score(true_labels, \n",
    "                                               predicted_labels,\n",
    "                                               average='weighted'),\n",
    "                        4))\n",
    "    print('Recall:', np.round(\n",
    "                        metrics.recall_score(true_labels, \n",
    "                                               predicted_labels,\n",
    "                                               average='weighted'),\n",
    "                        4))\n",
    "    print('F1 Score:', np.round(\n",
    "                        metrics.f1_score(true_labels, \n",
    "                                               predicted_labels,\n",
    "                                               average='weighted'),\n",
    "                        4))\n",
    "                        \n",
    "\n",
    "def train_predict_model(classifier, \n",
    "                        train_features, train_labels, \n",
    "                        test_features, test_labels):\n",
    "    # build model    \n",
    "    classifier.fit(train_features, train_labels)\n",
    "    # predict using model\n",
    "    predictions = classifier.predict(test_features) \n",
    "    return predictions    \n",
    "\n",
    "\n",
    "def display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\n",
    "    \n",
    "    total_classes = len(classes)\n",
    "    level_labels = [total_classes*[0], list(range(total_classes))]\n",
    "\n",
    "    cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels, \n",
    "                                  labels=classes)\n",
    "    cm_frame = pd.DataFrame(data=cm, \n",
    "                            columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n",
    "                                                  labels=level_labels), \n",
    "                            index=pd.MultiIndex(levels=[['Actual:'], classes], \n",
    "                                                labels=level_labels)) \n",
    "    print(cm_frame) \n",
    "    \n",
    "def display_classification_report(true_labels, predicted_labels, classes=[1,0]):\n",
    "\n",
    "    report = metrics.classification_report(y_true=true_labels, \n",
    "                                           y_pred=predicted_labels, \n",
    "                                           labels=classes) \n",
    "    print(report)\n",
    "    \n",
    "    \n",
    "    \n",
    "def display_model_performance_metrics(true_labels, predicted_labels, classes=[1,0]):\n",
    "    print('Model Performance metrics:')\n",
    "    print('-'*30)\n",
    "    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\n",
    "    print('\\nModel Classification report:')\n",
    "    print('-'*30)\n",
    "    display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels, \n",
    "                                  classes=classes)\n",
    "    print('\\nPrediction Confusion Matrix:')\n",
    "    print('-'*30)\n",
    "    display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, \n",
    "                             classes=classes)\n",
    "\n",
    "\n",
    "def plot_model_decision_surface(clf, train_features, train_labels,\n",
    "                                plot_step=0.02, cmap=plt.cm.RdYlBu,\n",
    "                                markers=None, alphas=None, colors=None):\n",
    "    \n",
    "    if train_features.shape[1] != 2:\n",
    "        raise ValueError(\"X_train should have exactly 2 columnns!\")\n",
    "    \n",
    "    x_min, x_max = train_features[:, 0].min() - plot_step, train_features[:, 0].max() + plot_step\n",
    "    y_min, y_max = train_features[:, 1].min() - plot_step, train_features[:, 1].max() + plot_step\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "    clf_est = clone(clf)\n",
    "    clf_est.fit(train_features,train_labels)\n",
    "    if hasattr(clf_est, 'predict_proba'):\n",
    "        Z = clf_est.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,1]\n",
    "    else:\n",
    "        Z = clf_est.predict(np.c_[xx.ravel(), yy.ravel()])    \n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=cmap)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    y_enc = le.fit_transform(train_labels)\n",
    "    n_classes = len(le.classes_)\n",
    "    plot_colors = ''.join(colors) if colors else [None] * n_classes\n",
    "    label_names = le.classes_\n",
    "    markers = markers if markers else [None] * n_classes\n",
    "    alphas = alphas if alphas else [None] * n_classes\n",
    "    for i, color in zip(range(n_classes), plot_colors):\n",
    "        idx = np.where(y_enc == i)\n",
    "        plt.scatter(train_features[idx, 0], train_features[idx, 1], c=color,\n",
    "                    label=label_names[i], cmap=cmap, edgecolors='black', \n",
    "                    marker=markers[i], alpha=alphas[i])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_model_roc_curve(clf, features, true_labels, label_encoder=None, class_names=None):\n",
    "    \n",
    "    ## Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    if hasattr(clf, 'classes_'):\n",
    "        class_labels = clf.classes_\n",
    "    elif label_encoder:\n",
    "        class_labels = label_encoder.classes_\n",
    "    elif class_names:\n",
    "        class_labels = class_names\n",
    "    else:\n",
    "        raise ValueError('Unable to derive prediction classes, please specify class_names!')\n",
    "    n_classes = len(class_labels)\n",
    "    y_test = label_binarize(true_labels, classes=class_labels)\n",
    "    if n_classes == 2:\n",
    "        if hasattr(clf, 'predict_proba'):\n",
    "            prob = clf.predict_proba(features)\n",
    "            y_score = prob[:, prob.shape[1]-1] \n",
    "        elif hasattr(clf, 'decision_function'):\n",
    "            prob = clf.decision_function(features)\n",
    "            y_score = prob[:, prob.shape[1]-1]\n",
    "        else:\n",
    "            raise AttributeError(\"Estimator doesn't have a probability or confidence scoring system!\")\n",
    "        \n",
    "        fpr, tpr, _ = roc_curve(y_test, y_score)      \n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label='ROC curve (area = {0:0.2f})'\n",
    "                                 ''.format(roc_auc),\n",
    "                 linewidth=2.5)\n",
    "        \n",
    "    elif n_classes > 2:\n",
    "        if hasattr(clf, 'predict_proba'):\n",
    "            y_score = clf.predict_proba(features)\n",
    "        elif hasattr(clf, 'decision_function'):\n",
    "            y_score = clf.decision_function(features)\n",
    "        else:\n",
    "            raise AttributeError(\"Estimator doesn't have a probability or confidence scoring system!\")\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        ## Compute micro-average ROC curve and ROC area\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "        ## Compute macro-average ROC curve and ROC area\n",
    "        # First aggregate all false positive rates\n",
    "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "        # Then interpolate all ROC curves at this points\n",
    "        mean_tpr = np.zeros_like(all_fpr)\n",
    "        for i in range(n_classes):\n",
    "            mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "        # Finally average it and compute AUC\n",
    "        mean_tpr /= n_classes\n",
    "        fpr[\"macro\"] = all_fpr\n",
    "        tpr[\"macro\"] = mean_tpr\n",
    "        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "        ## Plot ROC curves\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "                 label='micro-average ROC curve (area = {0:0.2f})'\n",
    "                       ''.format(roc_auc[\"micro\"]), linewidth=3)\n",
    "\n",
    "        plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "                 label='macro-average ROC curve (area = {0:0.2f})'\n",
    "                       ''.format(roc_auc[\"macro\"]), linewidth=3)\n",
    "\n",
    "        for i, label in enumerate(class_labels):\n",
    "            plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                                           ''.format(label, roc_auc[i]), \n",
    "                     linewidth=2, linestyle=':')\n",
    "    else:\n",
    "        raise ValueError('Number of classes should be atleast 2 or more')\n",
    "        \n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', max_iter=100, C=1)\n",
    "sgd = SGDClassifier(loss='hinge', n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "('Accuracy:', 0.8095)\n",
      "('Precision:', 0.79479999999999995)\n",
      "('Recall:', 0.8095)\n",
      "('F1 Score:', 0.77500000000000002)\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.30      0.42        40\n",
      "           2       1.00      0.37      0.54        19\n",
      "           3       0.73      0.32      0.44        25\n",
      "           4       0.66      0.30      0.41        83\n",
      "           5       0.82      0.99      0.90       463\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       630\n",
      "   macro avg       0.78      0.46      0.54       630\n",
      "weighted avg       0.79      0.81      0.78       630\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "          Predicted:               \n",
      "                   1  2  3   4    5\n",
      "Actual: 1         12  0  0   4   24\n",
      "        2          1  7  0   4    7\n",
      "        3          2  0  8   2   13\n",
      "        4          1  0  2  25   55\n",
      "        5          1  0  1   3  458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dinodjakovac/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dinodjakovac/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model on BOW features\n",
    "lr_bow_predictions = train_predict_model(classifier=lr, \n",
    "                                             train_features=cv_train_features, train_labels=sentiments_train,\n",
    "                                             test_features=cv_test_features, test_labels=sentiments_test)\n",
    "display_model_performance_metrics(true_labels=sentiments_test, predicted_labels=lr_bow_predictions,\n",
    "                                      classes=[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "('Accuracy:', 0.73170000000000002)\n",
      "('Precision:', 0.5403)\n",
      "('Recall:', 0.73170000000000002)\n",
      "('F1 Score:', 0.62160000000000004)\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        40\n",
      "           2       0.00      0.00      0.00        19\n",
      "           3       0.00      0.00      0.00        25\n",
      "           4       0.00      0.00      0.00        83\n",
      "           5       0.74      1.00      0.85       463\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       630\n",
      "   macro avg       0.15      0.20      0.17       630\n",
      "weighted avg       0.54      0.73      0.62       630\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "          Predicted:              \n",
      "                   1  2  3  4    5\n",
      "Actual: 1          0  0  0  0   40\n",
      "        2          0  0  0  1   18\n",
      "        3          0  0  0  0   25\n",
      "        4          0  0  0  0   83\n",
      "        5          0  0  0  2  461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dinodjakovac/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dinodjakovac/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dinodjakovac/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dinodjakovac/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dinodjakovac/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model on TF-IDF features\n",
    "lr_tfidf_predictions = train_predict_model(classifier=lr, \n",
    "                                               train_features=tv_train_features, train_labels=sentiments_train,\n",
    "                                               test_features=tv_test_features, test_labels=sentiments_test)\n",
    "display_model_performance_metrics(true_labels=sentiments_test, predicted_labels=lr_tfidf_predictions,\n",
    "                                      classes=[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "('Accuracy:', 0.80000000000000004)\n",
      "('Precision:', 0.79039999999999999)\n",
      "('Recall:', 0.80000000000000004)\n",
      "('F1 Score:', 0.78420000000000001)\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.35      0.47        40\n",
      "           2       1.00      0.42      0.59        19\n",
      "           3       0.71      0.40      0.51        25\n",
      "           4       0.49      0.43      0.46        83\n",
      "           5       0.85      0.94      0.89       463\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       630\n",
      "   macro avg       0.75      0.51      0.58       630\n",
      "weighted avg       0.79      0.80      0.78       630\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "          Predicted:                \n",
      "                   1  2   3   4    5\n",
      "Actual: 1         14  0   1   7   18\n",
      "        2          2  8   0   4    5\n",
      "        3          0  0  10   5   10\n",
      "        4          2  0   0  36   45\n",
      "        5          2  0   3  22  436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dinodjakovac/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# SGD model on Countvectorizer\n",
    "sgd_bow_predictions = train_predict_model(classifier=sgd, \n",
    "                                             train_features=cv_train_features, train_labels=sentiments_train,\n",
    "                                             test_features=cv_test_features, test_labels=sentiments_test)\n",
    "display_model_performance_metrics(true_labels=sentiments_test, predicted_labels=sgd_bow_predictions,\n",
    "                                      classes=[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "('Accuracy:', 0.83020000000000005)\n",
      "('Precision:', 0.81679999999999997)\n",
      "('Recall:', 0.83020000000000005)\n",
      "('F1 Score:', 0.81610000000000005)\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.45      0.55        40\n",
      "           2       0.78      0.37      0.50        19\n",
      "           3       0.73      0.44      0.55        25\n",
      "           4       0.60      0.51      0.55        83\n",
      "           5       0.87      0.96      0.91       463\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       630\n",
      "   macro avg       0.74      0.55      0.61       630\n",
      "weighted avg       0.82      0.83      0.82       630\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "          Predicted:                \n",
      "                   1  2   3   4    5\n",
      "Actual: 1         18  0   3   4   15\n",
      "        2          5  7   0   3    4\n",
      "        3          2  2  11   3    7\n",
      "        4          1  0   1  42   39\n",
      "        5          0  0   0  18  445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dinodjakovac/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# SGD model on TF-IDF\n",
    "sgd_tfidf_predictions = train_predict_model(classifier=sgd, \n",
    "                                                train_features=tv_train_features, train_labels=sentiments_train,\n",
    "                                                test_features=tv_test_features, test_labels=sentiments_test)\n",
    "display_model_performance_metrics(true_labels=sentiments_test, predicted_labels=sgd_tfidf_predictions,\n",
    "                                      classes=[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dinodjakovac/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "('Accuracy:', 0.81430000000000002)\n",
      "('Precision:', 0.80049999999999999)\n",
      "('Recall:', 0.81430000000000002)\n",
      "('F1 Score:', 0.78300000000000003)\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.62      0.20      0.30        40\n",
      "           2       0.88      0.37      0.52        19\n",
      "           3       0.75      0.36      0.49        25\n",
      "           4       0.76      0.41      0.53        83\n",
      "\n",
      "   micro avg       0.74      0.35      0.47       167\n",
      "   macro avg       0.60      0.27      0.37       167\n",
      "weighted avg       0.73      0.35      0.47       167\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "          Predicted:             \n",
      "                   0  1  2  3   4\n",
      "Actual: 0          0  0  0  0   0\n",
      "        1          0  8  0  2   3\n",
      "        2          0  0  7  0   2\n",
      "        3          0  0  0  9   0\n",
      "        4          0  5  0  0  34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dinodjakovac/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dinodjakovac/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/dinodjakovac/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dinodjakovac/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/dinodjakovac/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dinodjakovac/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# RandomForest model on TF-IDF\n",
    "rfc_tfidf_predictions = train_predict_model(classifier=rfc, \n",
    "                                                train_features=tv_train_features, train_labels=sentiments_train,\n",
    "                                                test_features=tv_test_features, test_labels=sentiments_test)\n",
    "display_model_performance_metrics(true_labels=sentiments_test, predicted_labels=rfc_tfidf_predictions,\n",
    "                                      classes=[0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "X = df_train_1['verified_reviews']\n",
    "y = df_train_1['rating']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X)\n",
    "#print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shape of Sparse Matrix: ', (3150, 4044))\n",
      "('Amount of Non-Zero occurrences: ', 60852)\n",
      "Density: 0.477697706184\n"
     ]
    }
   ],
   "source": [
    "X = vectorizer.transform(X)\n",
    "print('Shape of Sparse Matrix: ', X.shape)\n",
    "print('Amount of Non-Zero occurrences: ', X.nnz)\n",
    "# Percentage of non-zero values\n",
    "density = (100.0 * X.nnz / (X.shape[0] * X.shape[1]))\n",
    "print('Density: {}'.format((density)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.29      0.38        34\n",
      "           2       0.57      0.20      0.30        20\n",
      "           3       0.70      0.30      0.42        46\n",
      "           4       0.71      0.46      0.56       119\n",
      "           5       0.82      0.96      0.88       569\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       788\n",
      "   macro avg       0.67      0.44      0.51       788\n",
      "weighted avg       0.78      0.80      0.77       788\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Testing the model\n",
    "predictions = rfc.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_train_1['verified_reviews']\n",
    "y = df_train_1['rating']\n",
    "\n",
    "# Vectorizing model\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X)\n",
    "\n",
    "X = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.24      0.32        38\n",
      "           2       1.00      0.16      0.27        32\n",
      "           3       0.82      0.26      0.39        54\n",
      "           4       0.73      0.40      0.52       127\n",
      "           5       0.82      0.98      0.89       694\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       945\n",
      "   macro avg       0.77      0.41      0.48       945\n",
      "weighted avg       0.80      0.80      0.77       945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Testing model\n",
    "predictions = rfc.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
